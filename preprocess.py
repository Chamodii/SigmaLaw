# -*- coding: utf-8 -*-
"""preprocess

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-WizjCdllD7M0uHHfnmF0wgP8oTHRL3K
"""

#Configure the path for the stanfordcorenlp
#path =

import json
from stanfordcorenlp import StanfordCoreNLP

nlp = StanfordCoreNLP(path, quiet=False)
props = {'annotators': 'tokenize, ssplit, pos, lemma, parse, ner, coref, kbp, depparse', 'pipelineLanguage': 'en'}

def build_complete_ner(word, ner, l):
  if(l[0].get('ner') == ner):
    word = word + " " + build_complete_ner(l[0].get("word"), l[0].get('ner'), l[1:len(l)])
  return word

# To update parties based on ner
def NER(sentences):
  replace_dict={}
  ner = []
    
  for each in sentences:
    q = each.get("tokens")

    for j in range(0,len(q)):
      if(q[j].get("ner") == "PERSON" or q[j].get("ner") == "ORGANIZATION"):
        word = build_complete_ner(q[j].get("word"), q[j].get("ner"), q[j+1 : len(q)])

        #Build the prefix
        if(q[j].get("ner") == "PERSON"):
            prefix = "P"
        else:
            prefix = "O"
        prefix = prefix + str(len(ner)+1) + "$"
   
        if(j==0):
          ner.append(word)
          words = word.split(" ")
          for l in words:
            replace_dict[l] = (prefix+l)
        if(j!=0 and q[j-1].get("ner") != q[j].get("ner")):
          ner.append(word)
          words = word.split(" ")
          for l in words:
            replace_dict[l] = (prefix+l)
  return replace_dict

def preprocess(text):
  result = json.loads(nlp.annotate(text, properties=props))
  sentences = result['sentences']
  replace_dict = NER(sentences)
  for each in replace_dict.keys():
    text = text.replace(each, replace_dict[each])
  return text

text = "Petitioner Jae Lee and Rebecca Black moved to United States."

print(preprocess(text))
